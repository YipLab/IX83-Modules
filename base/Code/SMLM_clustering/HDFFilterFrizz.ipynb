{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d78aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea911e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "488 1 - 3\n",
    "561 1 - 3\n",
    "647 1.5-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1922e7-52c8-4f64-b00d-c2919f18235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"\\\\\\\\5.5.5.250\\\\share01\\\\yipgroup\\\\Au_Aaron\\\\02164-FRIZZ_SM\\\\290524\\\\\"\n",
    "trials = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "suffix = \"_MMStack_Default.ome_locs_undrift\"\n",
    "suffix2 = \"_MMStack_Default.ome_locs\"\n",
    "num = 5\n",
    "\n",
    "frame = 1000\n",
    "lp = 0.275\n",
    "min_ph = 500\n",
    "max_ph = 1750\n",
    "min_sig = 1\n",
    "max_sig = 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac15ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in trials:\n",
    "    for i in [0,1,2,3,4]:\n",
    "        file = t + \"_\" + str(i+1)\n",
    "        try:\n",
    "            with h5py.File(location + file + \"\\\\\" + file + suffix + \".hdf5\",\"r\") as f:\n",
    "                dat = f['locs'][...]\n",
    "        except:\n",
    "            print(\"ISSUE AT \" + file)\n",
    "            with h5py.File(location + file + \"\\\\\" + file + suffix2 + \".hdf5\",\"r\") as f:\n",
    "                dat = f['locs'][...]\n",
    "        data = np.rec.array(dat, dtype=dat.dtype)\n",
    "\n",
    "        #Filter data \n",
    "        data = data[((data['lpx']**2 + data['lpy']**2) <= lp**2)\n",
    "                   & (data['photons'] < max_ph) & (data['photons'] > min_ph)\n",
    "                   & (data['sx']**2 + data['sy']**2 <= max_sig**2)\n",
    "                    & (data['sx']**2 + data['sy']**2 >= min_sig**2)]\n",
    "\n",
    "        #Save as new HDF5 file\n",
    "        with h5py.File(location + file + \".hdf5\",'w') as f:\n",
    "            f.create_dataset(\"locs\", data = data)\n",
    "    \n",
    "        #Ammend YAML file\n",
    "        new_doc = {\n",
    "            'Generated by': 'HDF combiner',\n",
    "            'bg': None,\n",
    "            'ellipticity': None,\n",
    "            'frame': None,\n",
    "            'lpx': [0, lp],\n",
    "            'lpy': [0, lp],\n",
    "            'net_gradient': None,\n",
    "            'photons': [min_ph, max_ph],\n",
    "            'sx': [min_sig, max_sig],\n",
    "            'sy': [min_sig, max_sig],\n",
    "            'x': None,\n",
    "            'y': None    \n",
    "        }\n",
    "\n",
    "        with open(location+file+\"\\\\\"+ file + suffix + \".yaml\", \"r\") as stream:\n",
    "            docs = list(yaml.load_all(stream, Loader=yaml.UnsafeLoader))\n",
    "\n",
    "        do = []\n",
    "        for doc in docs:\n",
    "            do.append(doc)    \n",
    "        do.append(new_doc)\n",
    "\n",
    "        with open(location + file + \".yaml\", \"w\") as stream:\n",
    "            yaml.dump_all(do, stream, default_flow_style=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
